\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% Idioma e tipografia
\usepackage[brazilian]{babel}
\usepackage{csquotes}
\usepackage{lmodern}
\usepackage{microtype}

% Layout e recursos básicos
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{bookmark}

\emergencystretch=2em
\cleardoublepage
\pagenumbering{arabic}

% Matemática e teoremas (essencial só se você usa)
\usepackage{amsmath,amssymb,amsthm}

% Tabelas em paisagem e colunas flexíveis
% \usepackage{pdflscape}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{ragged2e}
\usepackage{array} % para \newcolumntype
\newcolumntype{Y}{>{\RaggedRight\arraybackslash}X}
\usepackage{rotating} % para sidewaystable/sideways


% Bibliografia ABNT numerada
\usepackage[
  backend=biber,
  style=abnt,
  sorting=none,
  giveninits=true,
  uniquename=false,
  doi=false,
  isbn=false,
  url=false,
  language=brazil,
  scbib,
  ittitles,
  justify
]{biblatex}
\addbibresource{refs.bib} % ← caminho corrigido



% ======= PADRONIZAÇÃO PARA A TABELA MDRE =======

% Coluna flexível "Y" (se ainda não tiver)
% \usepackage{tabularx,booktabs,ragged2e,array}
% \newcolumntype{Y}{>{\RaggedRight\arraybackslash}X}

% 1) Vocabulário controlado (sempre em SMALL CAPS):
% force medium series inside \textsc to avoid requesting a bold small-caps font (bx/sc)
\newcommand{\Static}{{\mdseries\textsc{Estático}}}
\newcommand{\Dynamic}{{\mdseries\textsc{Dinâmico}}}
\newcommand{\Hybrid}{{\mdseries\textsc{Híbrido}}}
\newcommand{\Comp}{{\mdseries\textsc{Compreensão}}}
\newcommand{\Redoc}{{\mdseries\textsc{Redocumentação}}}
\newcommand{\Mig}{{\mdseries\textsc{Migração}}}
\newcommand{\Quali}{{\mdseries\textsc{Qualidade}}}

% 2) Macros para setas e encadeamentos:
\newcommand{\ctoa}{\(\text{Código} \rightarrow \text{AST}\)}
\newcommand{\atoxi}{\(\text{AST} \rightarrow \text{IM}\)}   % IM = modelo intermediário
\newcommand{\imtoxml}{\(\text{IM} \rightarrow \text{XML}\)}
\newcommand{\imtomdl}{\(\text{IM} \rightarrow \text{UML}\)}
\newcommand{\tmtomdl}{\(\text{T2M/M2M} \rightarrow \text{UML}\)}
\newcommand{\xtoSeq}{\(\rightarrow \text{UML Sequência}\)}
\newcommand{\xtoClass}{\(\rightarrow \text{UML Classe}\)}
\newcommand{\xtoAct}{\(\rightarrow \text{UML Atividade}\)}

% 3) Abreviações de ferramentas (consistentes):
\newcommand{\EMF}{Eclipse/EMF}
\newcommand{\UMLtwo}{UML2}
\newcommand{\PlantUML}{PlantUML}
\newcommand{\JavaParser}{JavaParser}

% 4) Formato da célula “Aspecto”: Técnica ; Objetivo(s)
%    Ex.: \Static; \Comp/\Redoc (estrutura + comportamento)

% 5) Formato da célula “Técnica/Transformação”:
%    Use sempre cadeia com “→”, negrite elementos-chaves e padronize nomes.
%    Ex.: Código → AST → \textbf{IM(XML)} → T2M/M2M → \textbf{UML2}
%
% 6) Formato da célula “Validação”:
%    [tipo de evidência; dataset/projetos; métrica(s) ou avaliação; nota curta]
%    Ex.: OSS (9 projetos, 2640 classes); AUC=0.73; custo de rótulo 10%

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{0cm}
        
            \includegraphics[width=0.5\textwidth]{Images/Logo_FGV.png} 
            
        \vspace{1.5cm}
        \large
        
        Ciência de Dados e I.A.\\
        Escola de Matemática Aplicada\\
        Fundação Getúlio Vargas\\

        \vspace{1cm}  
    
        \Large
        Engenharia de Requisitos
            
        \vspace{2cm}
        
        \vspace{0.25cm}

        \Huge \textbf{Proposta de TCC} \\ 
        \vspace{0.5cm}
        \huge \textbf{LLM para Engenharia de Requisitos}
        \vspace{3.6cm}
        
        \large
                Aluno: Isabela Yabe\\
                Orientador: Rafael de Pinho André\\
                Escola de Matemática Aplicada, FGV/EMAp \\
                Rio de Janeiro - RJ.
        \vfill
            
        \vspace{0.8cm}  
        
        Rio de Janeiro, 2025
            
    \end{center}
\end{titlepage}
\newpage
\pagenumbering{roman}
\tableofcontents

\newpage
\pagenumbering{arabic}

\section{Resumo}

\section{Resumo}
 Este trabalho investiga se é possível recuperar artefatos de requisitos, em particular diagramas de casos de uso, diretamente a partir de sistemas implementados em Python, combinando análise estática de código e técnicas recentes de representação semântica com \textit{Large Language Models} (LLMs).

A proposta parte da \textit{Abstract Syntax Tree} (AST) do código-fonte, tratada como modelo intermediário em um fluxo de \textit{Model-Driven Reverse Engineering} (MDRE). Sobre essa estrutura, são extraídas \textit{features} estruturais (tipo de nó, escopo, relações de chamada) e textuais (nomes, docstrings, comentários), que alimentam um encoder de nós e uma GNN responsável por produzir embeddings semântico-estruturais do arquivo. A partir desses embeddings, métodos públicos são identificados como candidatos a casos de uso e agrupados por similaridade semântica, enquanto o grafo de chamadas fornece relações de dependência entre casos.

O resultado esperado é um processo de redocumentação capaz de gerar diagramas de casos de uso em \textit{PlantUML} a partir de código Python, preservando a semântica observada e oferecendo uma visão de alto nível do sistema. A principal contribuição é aproximar engenharia de requisitos e engenharia reversa ao mostrar como LLMs e modelos de código orientados por AST podem apoiar a recuperação de requisitos em cenários em que a documentação está ausente ou desatualizada.

\section{Introdução}

A engenharia de software estuda e avalia métodos capazes de aproximar o código-fonte da linguagem natural. Essa busca se manifesta em duas vertentes complementares: a interação com o usuário final e a comunicação entre os próprios desenvolvedores. 

Este estudo fundamenta-se em autores que defendem o desenvolvimento estruturado e orientado ao usuário, projetado a partir da visão e das necessidades de quem utiliza o sistema, e não apenas da estrutura interna ou das preferências de quem o desenvolve. Essa perspectiva deu origem a princípios de design centrados na função e no comportamento observável do sistema, enfatizando que a organização do código deve refletir a experiência do usuário e os fluxos de interação previstos. 

\textcite{yourdon1979structured} descrevem o processo tradicional de desenvolvimento de software como uma cadeia de tradução sucessiva: o diálogo entre o proprietário do produto, o usuário e o analista é continuamente reinterpretado pelo engenheiro de requisitos, pelo designer e pelo programador, conforme ilustrado na Figura~\ref{fig:cadeia_traducao_constantine1979}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{Images/diagrams/fluxo_info.png}
  \caption{cadeia de tradução de requisitos segundo Constantine \(1979\).}
  \label{fig:cadeia_traducao_constantine1979}
\end{figure}

Cada etapa dessa cadeia implica a perda ou distorção de parte do significado original do usuário, o que pode resultar em comportamentos apenas próximos ao desejado. Diante disso, os autores propõem o projeto estruturado, cujo ponto inicial é a clareza e a visibilidade das decisões e atividades envolvidas, promovendo uma compreensão compartilhada e garantindo que o design reflita as intenções originais do sistema.

\subsection{Problematização}

Com o mesmo intuito de tornar o comportamento do sistema visível e compreensível, surge a modelagem de casos de uso como um instrumento de unificação entre requisitos, design e usabilidade. Segundo \textcite{booch1999unified}, nenhum sistema existe isoladamente: todo sistema relevante interage com atores, humanos ou automáticos, que esperam comportamentos previsíveis. O diagrama de casos de uso permite que analistas e desenvolvedores discutam o comportamento do sistema sem se prender aos detalhes da implementação, oferecendo uma linguagem comum e verificável para representar comportamentos.

Autores posteriores ampliaram essa discussão para o nível do código, enfatizando a necessidade de que o código não seja apenas executável, mas também compreensível. Como sintetiza \textcite{fowler2018refactoring}, “qualquer tolo escreve um código que um computador possa entender; bons programadores escrevem código que seres humanos possam entender”.

Entretanto, a legibilidade do código, por si só, não substitui a documentação de requisitos. Enquanto o código explica como o sistema se comporta, a documentação torna explícito por que ele deve se comportar assim. Segundo \textcite{sommerville1997requirements}, a documentação de requisitos atua como um contrato conceitual entre usuários, analistas e desenvolvedores, garantindo o alinhamento entre o comportamento implementado e as expectativas de negócio. Quando essa documentação falta ou envelhece, a legibilidade do código torna-se o principal ponto de apoio para reconstruir as intenções originais, o que representa um desafio na manutenção e evolução de sistemas legados.

\subsection{Questão e hipótese}

Se o código é um texto escrito para ser lido por humanos, então suas palavras, nomes e estruturas carregam pistas úteis sobre o que o sistema faz e para quem. Partindo dessa premissa, pergunta-se: é possível reconstruir casos de uso a partir do código-fonte, combinando análise estrutural e interpretação semântica automatizada?

A hipótese deste trabalho é que técnicas de representação semântica, como embeddings e \textit{Large Language Models} (LLMs), quando aplicadas sobre estruturas abstratas do código, como a \textit{Abstract Syntax Tree} (AST), podem viabilizar a reconstrução de artefatos de alto nível, como diagramas de casos de uso, mesmo na ausência de documentação formal.

\subsection{Objetivos}

O objetivo geral deste trabalho é propor um processo de redocumentação automatizada capaz de gerar diagramas de casos de uso a partir do código-fonte, preservando a semântica do sistema original.
Para isso, o método combina:

\textcite{Bruneliere2010MoDisco} o MoDisco, um framework genérico para engenharia reversa orientada por modelos (Model-Driven Reverse Engineering — MDRE). Ele sugere resumirmos os sistemas em modelos, uma estrutura mais homogênea. A principal ideia é recuperar modelos existentes no sistema. O processo é dividido em duas fases, descoberta do modelo e compreensão do modelo. Na fase de descoberta, um componente chamado discoverer extrai informações do código-fonte, dados brutos, documentações e artefatos disponíveis. Passando estas informações para uma representação da estrutura do sistema. Já na fase de compreensão, o conteúdo desse modelo é analisado e transformado em representações de alto nível, diagramas, métricas ou relatórios, que podem servir à redocumentação, à modernização de sistemas ou à análise de qualidade.

A partir dessa arquitetura, adotaremos a mesma lógica de abstração proposta por \textcite{tonella2007reverse}, utilizando uma representação sintática reduzida do código-fonte que preserva apenas os elementos essenciais ao fluxo de objetos, criações, atribuições e chamadas, e ignora instruções de controle. Essa simplificação torna possível construir a Abstract Syntax Tree (AST) como modelo intermediário, permitindo representar a estrutura e os diagramas de casos de uso.

Esse tipo de investigação é definido por \textcite{chikofsky1990reverse} como \textit{Redocumentation} em \textit{Reverse engineering}, ou seja, engenharia reversa com foco em redocumentação, no sentido de criar representações de abstração do sistema existente, destinadas à leitura humana, sem alterar o comportamento do software. 

Além da linguagem abstrata, este trabalho incorpora informações semânticas extraídas diretamente das \textit{docstrings}, comentários e nomenclaturas do código. Esses elementos textuais são tratados como extensões dos objetos, pois também comunicam intenções, objetivos e relações entre entidades. Com o apoio de \textit{Large Language Models} (LLMs), essas evidências são analisadas de forma contextual, permitindo inferir papéis, objetivos e interações que não estão explicitamente representados nas chamadas ou estruturas do código.

Dessa forma, o processo de redocumentação combina a análise estrutural, que descreve como os objetos estão correlacionados, e a análise semântica, que interpreta o vocabulário interno do sistema revelando as intenções dos desenvolvedores. 

\subsection{Relevância}

Este trabalho contribui para auxiliar desenvolvedores durante a codificação e também na compreensão de sistemas sem documentação. Ao gerar visões de alto nível do sistema, especificamente casos de uso, a proposta facilita a compreensão e as interações entre componentes. 

Segundo \textcite{larman2002applying}, os casos de uso não apenas documentam funcionalidades, mas representam um instrumento de convergência entre analistas, projetistas e programadorea. Em contextos dinâmicos, casos de uso bem definidos apoiam a priorização de requisitos, a validação de comportamentos e a manutenção de uma visão compartilhada do sistema, mesmo diante de mudanças constantes.

Embora a maioria dos estudos sobre Model-Driven Reverse Engineering (MDRE) e redocumentação concentre-se em linguagens como Java, este trabalho propõe uma abordagem direcionada à linguagem Python, que, segundo o TIOBE Index (2025), mantém-se como a linguagem mais popular globalmente. 

Por fim, além de oferecer uma nova aplicação prática de Large Language Models na engenharia de software, o estudo propõe uma ponte entre engenharia de requisitos e engenharia reversa, reforçando a ideia de que compreender um sistema começa por compreender seu código, não apenas como sequência de instruções, mas como expressão das intenções humanas que lhe deram origem.

\section{Revisão literária}

A revisão tem o objetivo de compreender o estado da arte das abordagens de engenharia reversa que partem de código-fonte e produzem artefatos de alto nível, como diagramas UML. Para garantir uma análise sistemática e comparável entre diferentes propostas, foram definidas perguntas de pesquisa (\textit{Research Questions — RQs}) que orientam a coleta e síntese dos dados extraídos dos estudos selecionados.

\begin{itemize}
  \item \textbf{RQ1.} Em quais linguagens e domínios as abordagens que partem de código-fonte foram aplicadas?
  \item \textbf{RQ2.} Quais modelos/artefatos de alto nível são gerados?
  \item \textbf{RQ3.} Qual aspecto é privilegiado (estático, dinâmico, híbrido) e com qual objetivo (compreensão, redocumentação, migração, qualidade)?
  \item \textbf{RQ4.} Quais técnicas e transformações viabilizam a passagem do código para o modelo de alto nível?
  \item \textbf{RQ5.} Quais ferramentas/frameworks são utilizados?
  \item \textbf{RQ6.} Como as abordagens são validadas e com que qualidade prática?
\end{itemize}

A coleta dos estudos seguiu uma estratégia sistemática de busca em bases reconhecidas, IEEE Xplore e ACM Digital Library no período de 2015 a 2025.

A query se estrutura na combinação de três blocos temáticos:

\begin{itemize}
  \item ("Abstract": "MDRE" OR "reverse engineering" OR "model driven reverse engineering" OR "design recovery")
  \item ("Abstract": "UML" OR "UML class diagram" OR "UML activity diagram" OR "UML sequence diagram" OR "UML models" OR "Diagram")
  \item: ("Abstract": "static analysis" OR "source code analysis" OR "abstract syntax tree" OR "AST" OR "text-to-model" OR "T2M" OR "parser" OR "source code" OR "parsing")
\end{itemize}

Foram incluídos apenas os estudos que propõem uma abordagem de engenharia reversa aplicada à geração de modelos UML (classes, atividades ou sequência) diretamente a partir do código-fonte.
  
Foram excluídos os trabalhos que se enquadravam em uma ou mais das seguintes categorias:
\begin{itemize}
  \item Foco em forward engineering ou geração de código.
  \item Estudos centrados em rastreabilidade ou anti-padrões.
  \item Trabalhos puramente empíricos ou teóricos sem proposta de transformação automatizada.
  \item Abordagens puramente dinâmicas.
\end{itemize}

Com base nos critérios de inclusão e exclusão, foram selecionados os seguintes estudos para análise detalhada:

\begin{itemize}
  \item A Model Driven Reverse Engineering Framework for Generating High Level UML Models From Java Source Code (2019).
  \item Condensing Class Diagrams With Minimal Manual Labeling Cost (2016). (parte do diagrama e aperfeiçoa)
  \item Enhancing Model-Driven Reverse Engineering Using Machine Learning (2024).
  \item Reverse Engineering of Source Code to Sequence Diagram Using Abstract Syntax Tree (2016).
  \item Towards a New Hybrid Approach of the Reverse Engineering of UML Sequence Diagram (2016).
  \item WIP: Generating Sequence Diagrams for Modern Fortran (2017).
\end{itemize}

\begin{sidewaystable}[p]
\centering
\scriptsize % Mudar o tamanho da fonte para caber melhor
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabularx}{\textheight}{Y Y Y Y Y Y Y}
\toprule
\textbf{Autores / Referência} &
\textbf{Linguagem / Domínio} & % Verde
\textbf{Modelo Gerado} & % Azul
\textbf{Aspecto} & % Laranja
\textbf{Técnica / Tipo de Transformação} & % Roxo
\textbf{Ferramenta / Framework} & % Cinza
\textbf{Validação / Estudo de Caso} \\ % Rosa
\midrule


\textcite{zhang2016j2x} &
Java; pequenos sistemas OO (eLib, Minesweeper, Blog, PayrollSys, myAlgsLib) &
UML Classe; UML Sequência &
Estático — compreensão, manutenção/redocumentação &
Código→AST→J2X; mapeamentos (gen./impl./assoc./dep.); sentenças simplif.→OFG; CFG+OFG→Sequência &
J2UML; JavaCC; Dom4j; J2X (DTD/XML) &
5 casos pequenos; acurácia: classes 96,4–100\%; relações 65,0–90,4\% \\

\textcite{yang2016condensing} &
Java; sistemas OO &
UML Classe (condensado) &
\Static; \Comp/\Redoc; estrutural &
\textbf{Extração de métricas (SDMetrics)} $\rightarrow$ Normalização (z-score) $\rightarrow$ \textbf{k-means clustering} $\rightarrow$ Random under-sampling $\rightarrow$ \textbf{Ensemble learning (Random Forest)} $\rightarrow$ diagrama condensado &
MagicDraw; SDMetrics; Random Forest; Windows 7 &
OSS (9 projetos, 2640 classes); AUC=0.73; custo de rótulo=10\%; teste de Wilcoxon e Cliff’s $\delta$ \\

\textcite{Fauzi2016AST} &
Java; sistemas orientados a objetos &
UML Sequência (comportamental) &
\Static; \Comp/\Redoc &
\textbf{Código} $\rightarrow$ \textbf{AST (JavaParser)} $\rightarrow$ \textbf{DFS pós-ordem} $\rightarrow$ \textbf{PlantUML (Seq)} &
REVUML; \JavaParser; \PlantUML &
126 casos de teste (8 categorias; geração correta e consistente de diagramas \\ 


\textcite{baidada2016hybrid} &
Java/Genérico; aplicações OO &
UML Sequência (HLSD) &
\textbf{Híbrido} (Estático + Dinâmico); Compreensão/Redocumentação (comportamento) &
CFG$\!\rightarrow$entradas; execuções+traços (filtro); traços$\!\rightarrow$CPN; CPN$\!\rightarrow$UML SD &
Sem ferramenta nominal; UML 2; instrumentação/VM/debugger; CPN (IR) &
Sem validação; futuro \\

\textcite{leatongkam2017generating} &
Fortran OO; computação científica e engenharia &
UML Classe; UML Sequência; modelo intermediário XMI &
Estático — compreensão e redocumentação &
Regras de mapeamento código $\rightarrow$ UML (OMG); parsing estático; árvore sintática; geração XMI $\rightarrow$ importação ArgoUML &
ForUML (extensão); ArgoUML; padrão OMG UML/XMI;&
\textit{Work in progress} \\

\textcite{Sabir2019MDRE} &
Java (sistemas legados orientados a objetos) &
UML \emph{Class Diagram} + \emph{Activity Diagram} (em pacote UML) &
Estático; objetivo: compreensão/redocumentação &
T2M/M2M em duas fases: Parser$\rightarrow$AST$\rightarrow$IM(XML) e mapeamentos IM$\rightarrow$UML (classe/atividade) &
Eclipse + UML2/EMF; JavaParser (IMD); (Papyrus/StarUML/Rational Rose na validação manual) &
Comparação especialista (modelos manuais vs. gerados), 5 estudos de caso; ATM e Amadeus descritos \\ 


\textcite{siala2024enhancing} &
Java; Python; sistemas legados &
UML Classe; OCL &
Estático — compreensão, redocumentação e migração &
código $\rightarrow$ tokenização/simplificação $\rightarrow$ geração textual UML/OCL intermediária(LLM) $\rightarrow$ model repair $\rightarrow$ diagramas UML/OCL &
Graphviz; PlantUML; Modelio; AgileUML; LLM &
Comparação MDRE: dois estudos de caso; correção semântica, completude e compreensibilidade \\

\bottomrule
\end{tabularx}
\caption{Síntese comparativa dos estudos selecionados.}
\label{tab:sintese_comparativa}
\end{sidewaystable}

\subsection{Análise sistemática da literatura}

A partir da síntese da Tabela~\ref{tab:sintese_comparativa}, organizamos os achados por eixo (RQ1–RQ6).

\paragraph{RQ1 — Linguagens e domínios.}
Predomina o ecossistema \textbf{Java} em sistemas orientados a objetos, tanto em estudos estruturais quanto comportamentais (\textcite{zhang2016j2x, yang2016condensing, Fauzi2016AST, Sabir2019MDRE}). Há ampliação pontual para \textbf{Fortran OO} em contexto de computação científica (\textcite{leatongkam2017generating}) e menção tanto a \textbf{Java} quanto a \textbf{Python} em proposta recente com LLMs (\textcite{siala2024enhancing}). Em síntese, o corpus avaliado é fortemente dominado por Java, Python surge como alvo ainda subexplorado.

\paragraph{RQ2 — Modelos/artefatos gerados.}
A produção concentra-se em \textbf{UML Classe} e \textbf{UML Sequência}. Em \textcite{zhang2016j2x}, ambos são gerados a partir de um pipeline \textit{código} $\rightarrow$ \textit{J2X} $\rightarrow$ \textit{OFG/CFG} $\rightarrow$ \textit{UML} (Classe+Sequência) . \textcite{leatongkam2017generating} propõe estender o \emph{ForUML} para também extrair \textbf{Sequência} a partir de Fortran OO, exportando um \textbf{XMI} intermediário para visualização (e.g., ArgoUML) . \textcite{Fauzi2016AST} derivam \textbf{Sequência} diretamente da \textbf{AST}, com saída em \emph{PlantUML} (Seq), abordagem estática focada em interações. \textcite{Sabir2019MDRE} incluem \textbf{Activity} além de \textbf{Class}, gerando “modelos UML de alto nível” (classe + atividade) a partir de um modelo intermediário (UML2) . \textcite{yang2016condensing} não “geram” um novo tipo de diagrama, mas \emph{condensam} \textbf{diagramas de classe} via métricas + \emph{ensemble learning}, reduzindo a complexidade visual ao destacar “classes importantes” (AUC, testes de Wilcoxon/Cliff’s $\delta$) . Em contraste, \textbf{Casos de Uso} aparecem sobretudo como enquadramento conceitual para Sequência, mas não como artefato recuperado dos códigos analisados, sinalizando uma lacuna na redocumentação de requisitos a partir de código.

\paragraph{RQ3 — Qual aspecto é privilegiado (estático, dinâmico, híbrido) e com qual objetivo?}
No conjunto analisado, prevalece de forma nítida o aspecto \textbf{\Static}, quase sempre orientado à \textbf{\Comp/\Redoc}. Os trabalhos clássicos da vertente estrutural e comportamental, como \textcite{zhang2016j2x} e \textcite{Fauzi2016AST}, operam integralmente sobre o código (sem execução), partindo de \emph{parsing}/AST e passando por representações intermediárias (p.\,ex., J2X) ou travessias específicas (DFS pós-ordem) para derivar, respectivamente, diagramas de Classe e Sequência. Em \textcite{leatongkam2017generating}, a mesma orientação estática se mantém ao estender o ForUML para Fortran OO via regras de mapeamento e exportação XMI; e em \textcite{Sabir2019MDRE}, trata-se de um processo estático T2M com fluxo código$\rightarrow$AST$\rightarrow$IM$\rightarrow$UML, com objetivo voltado à compreensão e redocumentação. Ainda sob a ótica estática, \textcite{yang2016condensing} não cria um novo artefato, mas trata o \emph{pós-processamento} do diagrama de classes via métricas e \emph{machine learning}, reduzindo a complexidade visual sem recorrer a dados de execução. Em contraste com esse predomínio, \textcite{baidada2016hybrid} introduzem um caminho \textbf{\Hybrid} (estático + dinâmico) para Sequência: gera-se um conjunto de entradas a partir do CFG, coletam-se traços por instrumentação/VM, sintetiza-se uma IR (\textit{Intermeadiate Representation}) comportamental em \emph{Colored Petri Nets} e, então, mapeia-se para UML. Por fim, \textcite{siala2024enhancing} preserva o caráter \textbf{\Static} ao integrar LLMs como camada semântica (texto intermediário UML/OCL seguido de \emph{model repair}), ampliando o objetivo para \textbf{migração} em sistemas legados e apontando uma inflexão do “estrutural puro” para um \emph{estrutural + semântico}. 

\paragraph{RQ4 — Técnicas e transformações.}
As abordagens convergem em um esqueleto MDRE que encadeia \emph{Text-to-Model} e \emph{Model-to-Model}: análise sintática do código (\emph{parsing}) para \textbf{AST} ou \textbf{IR} textual, seguida de mapeamentos para o metamodelo UML. Ainda assim, diferem nos \emph{intermediários}, nos operadores de fluxo usados para recuperar comportamento e no quanto incorporam \emph{semântica} além da sintaxe. Em \textcite{zhang2016j2x}, o núcleo é a \textbf{J2X} (DTD/XML), uma IR que padroniza elementos de linguagem; o diagrama de classes surge de metadados extraídos dessa IR, enquanto o diagrama de sequência resulta da \textbf{integração OFG+CFG} (rastros de objetos + fluxo de controle) para identificar \emph{lifelines}, \emph{messages} e \emph{combined fragments} (\textsf{alt}/\textsf{opt}/\textsf{loop}) de modo inteiramente estático. \textcite{Fauzi2016AST} elimina o XML e vai direto da \textbf{AST} (JavaParser) para \emph{Sequence}, guiado por uma travessia \textbf{DFS pós-ordem} com registro de variáveis, resolução de herança/polimorfismo e marcação de estruturas condicionais/iterativas; a apresentação é automatizada via \textbf{PlantUML}. Já \textcite{Sabir2019MDRE} formalizam o pipeline clássico \textbf{T2M/M2M} em duas fases: da AST para um \textbf{Intermediate Model (XML/EMF)} e, então, do IM (\textit{Intermeadiate Model}) para \textbf{UML} (Classe + \emph{Activity} por operação), com regras de transformação implementadas no ecossistema Eclipse/UML2. O \textbf{híbrido} de \textcite{baidada2016hybrid} desloca a recuperação comportamental para uma IR executável: um \textbf{CFG} orienta a geração de entradas; execuções instrumentadas produzem \emph{traces} filtrados; esses traços são sintetizados como \textbf{Colored Petri Nets (CPN)} e finalmente mapeados para \emph{UML Sequence}, capturando paralelismo e operadores combinados. Em domínio não-Java, \textcite{leatongkam2017generating} mantém a análise estática por \textbf{regras formais de mapeamento} (Fortran OO $\rightarrow$ UML), uma \emph{tree node structure} análoga à AST, e geração de \textbf{XMI} para importação/visualização no ArgoUML, expandindo o ForUML para \emph{Sequence}. Duas linhas recentes aplicam \emph{aprendizado}: \textcite{yang2016condensing} não cria um novo artefato, mas \textbf{condensa} o diagrama de classes com um pipeline \emph{métricas $\rightarrow$ normalização (z-score) $\rightarrow$ k-means $\rightarrow$ under-sampling $\rightarrow$ \emph{ensemble} (Random Forest)}, priorizando classes “importantes” e reduzindo a complexidade visual; e \textcite{siala2024enhancing} introduz \textbf{LLMs} como camada \emph{semântica}: o código é tokenizado/simplificado, traduzido para uma \textbf{representação textual intermediária UML/OCL}, submetida a \emph{model repair} e convertida em diagramas (PlantUML/Graphviz/Modelio). 

\paragraph{RQ5 — Ferramentas/frameworks.}
O ecossistema técnico das abordagens analisadas agrega \emph{parsers}/geradores UML, frameworks MDE e utilitários de visualização/mineração. Em \textcite{zhang2016j2x}, a cadeia J2X apoia-se na \textbf{J2UML} (orquestração), no \textbf{JavaCC} (geração do parser/AST), em \textbf{DOM4J} (manipulação XML) e no próprio \textbf{J2X (DTD/XML)} como IR; os experimentos reportam ambiente Windows 32-bit (3 GB RAM; Core 2 Duo). Em \textcite{yang2016condensing}, para “condensar” diagramas de classes, utilizam-se \textbf{MagicDraw} (recuperação de Classe), \textbf{SDMetrics} (métricas), e \textbf{Random Forest} (classificador), com relatos do ambiente \textit{Windows 7} (64-bit). A \textcite{Fauzi2016AST} (REVUML) integra \textbf{JavaParser} (AST) e \textbf{PlantUML} (renderização do Sequência), dispensando IR XML intermediária. Em \textcite{baidada2016hybrid}, não há ferramenta nominal de ponta a ponta: a coleta se dá por \textbf{instrumentação}/\textbf{JVM}/\textbf{debugger}, a IR comportamental usa \textbf{Colored Petri Nets} (sugerindo uso de \textit{CPN Tools}), e o mapeamento segue \textbf{UML 2}. Em \textcite{leatongkam2017generating}, a extensão da \textbf{ForUML} gera \textbf{XMI (OMG)} para importação no \textbf{ArgoUML} (visualização de Sequência). No framework \textcite{Sabir2019MDRE} (Src2MoF), o gerador baseia-se em \textbf{Eclipse}+\textbf{UML2/EMF} e o \textbf{JavaParser} integra o IMD; ferramentas como \textbf{Papyrus}/\textbf{StarUML}/\textbf{Rational Rose} são citadas apenas para comparação manual, não no pipeline automático. Por fim, \textcite{siala2024enhancing} combina \textbf{AgileUML}/\textbf{OMG MDA} com \textbf{LLMs} (camada semântica) e usa \textbf{Graphviz}, \textbf{PlantUML} e \textbf{Modelio} para materializar \textit{UML/OCL} (fase M2V).

\paragraph{RQ6 — Validação e qualidade prática.}
A avaliação varia de \textbf{estudos de caso pequenos com acurácia estrutural} (classes 96{,}4–100\%, relações 65{,}0–90{,}4) \parencite{zhang2016j2x}, a \textbf{testes sistemáticos} de geração de sequência \parencite{Fauzi2016AST}, e \textbf{comparação especialista} sem métricas quantitativas \parencite{Sabir2019MDRE}. \textcite{yang2016condensing} recorre a \textbf{AUC} e testes estatísticos (Wilcoxon, Cliff’s $\delta$) para condensação de classes. \textcite{baidada2016hybrid} não reporta validação empírica. Em suma, há carência de avaliações \emph{comparativas} com ground truth e métricas padronizadas na maioria dos trabalhos.

\section{Metodologia}

Este trabalho adota uma abordagem de \emph{Model-Driven Reverse Engineering} (MDRE), na qual o código-fonte da aplicação é tratado como modelo de origem e é progressivamente transformado em modelos de nível mais alto, culminando na geração de diagramas UML de casos de uso. Em vez de regras puramente simbólicas, a metodologia combina análise estática tradicional com técnicas de aprendizado de
máquina, utilizando embeddings de código e Redes Neurais de Grafos (GNNs) para
inferir estruturas funcionais e relações entre artefatos.

De forma simplificada, a cadeia de transformação pode ser descrita como:

\[
\text{Código-fonte} \rightarrow \text{AST} \rightarrow \text{TNodes} \rightarrow
\text{Grafos e embeddings} \rightarrow \text{Modelo de casos de uso} \rightarrow
\text{Diagrama UML}.
\]

Nesta abordagem, a AST enriquecida e o conjunto de \texttt{TNode}s formam o \emph{modelo intermediário estruturado}: uma representação sistemática do código-fonte que explicita entidades (classes, métodos, funções), relacionamentos sintáticos e metadados derivados por análise estática. Esse modelo atua como o primeiro nível de abstração acima do código, cumprindo o papel tradicional de um IM (Intermediate Model) em pipelines de Model-Driven Reverse Engineering (MDRE).

Sobre esse modelo estruturado é construída uma segunda camada de representação: um \emph{modelo intermediário vetorial}. Esse modelo é composto por embeddings gerados a partir da combinação de informações estruturais (features sintáticas, visibilidade, tipo de método, profundidade e métricas locais) e informações semânticas (texto extraído de nomes, docstrings e comentários), processadas por uma Rede Neural de Grafos (GNN). Esse nível vetorial não substitui o modelo estruturado; ele o complementa, fornecendo uma aproximação contínua das similaridades funcionais entre métodos.

A partir da integração dos dois modelos intermediários — o estruturado (AST/TNodes) e o vetorial (embeddings/GNN) — a ferramenta deriva o \emph{modelo de destino}, composto por: (i) o grafo de casos de uso, que sintetiza dependências estruturais e comportamentais entre métodos públicos; e (ii) o diagrama UML resultante, que organiza esses elementos em casos de uso primários, secundários e relações \emph{include}, \emph{extend}, generalização e dependência.

A metodologia está organizada em três etapas principais:

\begin{enumerate}
    \item \textbf{Construção e enriquecimento da AST} (\emph{ASTCore}): o código-fonte é analisado por meio de técnicas de análise estática, resultando na AST nativa do Python e em um conjunto de \texttt{TNode}s enriquecidos por passes especializados. Esse conjunto constitui o modelo intermediário estrutural, que captura entidades, relações sintáticas e metadados relevantes.

    \item \textbf{Geração de embeddings e grafos de código} (\emph{EmbeddingsApi}): o modelo intermediário estrutural é transformado em um modelo intermediário vetorial. Para isso, cada \texttt{TNode} é convertido em um embedding denso que integra informações estruturais e textuais, então, constrói-se o grafo da AST com pesos gaussianos nas arestas, sobre o qual uma GNN é aplicada para obter embeddings em nível de nó, arquivo e repositório.

    \item \textbf{Extração, inferência e seleção de casos de uso} (\emph{UsecaseApi}): a partir dos métodos públicos identificados no modelo intermediário, a ferramenta constrói o grafo de dependências entre candidatos a casos de uso, calcula métricas estruturais (fan-in, fan-out e papéis arquiteturais), aplica clusterização sobre os embeddings e executa heurísticas para inferir relações funcionais (\emph{include}, \emph{extend}, generalização e dependência). Essas heurísticas orientam também a seleção dos casos de uso representativos que compõem o modelo final exportado em PlantUML.
\end{enumerate}

As duas primeiras etapas da metodologia, a construção e enriquecimento da AST (\emph{ASTCore}) e a geração dos embeddings e grafos de código (\emph{EmbeddingsApi}), correspondem ao que \textcite{Bruneliere2010MoDisco} denominam \emph{model discovery}. No modelo de referência do MoDisco, a fase de descoberta é responsável por extrair informações do código-fonte e convertê-las em uma representação homogênea e estruturada. De maneira análoga, este trabalho utiliza análise estática e passes especializados para construir um modelo intermediário estruturado (AST enriquecida e \texttt{TNode}s), seguido por um modelo intermediário vetorial baseado em embeddings gerados por GNNs.

Já a terceira etapa, a extração, inferência e seleção de casos de uso (\emph{UsecaseApi}), materializa a fase de \emph{model understanding} proposta pelo MoDisco. Nessa fase, o modelo intermediário é interpretado: aplicam-se heurísticas estruturais e semânticas para identificar operações relevantes do sistema, inferir relações funcionais entre elas (\emph{include}, \emph{extend}, generalização e dependência) e selecionar os casos de uso mais representativos de cada grupo funcional. O resultado é um modelo de destino que sintetiza o comportamento exposto pelo código-fonte em uma representação de alto nível, posteriormente exportada como um diagrama UML.

É importante notar que, conforme argumentam \textcite{pereira2011recovering}, atores não são inferidos, pois não aparecem no código-fonte e dependem de conhecimento externo ao sistema. Assim, o modelo final deste trabalho é intencionalmente restrito aos casos de uso e às relações entre eles, sem propor reconstrução completa da modelagem original da UML.

\subsubsection{Construção da árvore sintática enriquecida}

A árvore sintática enriquecida é construída a partir da função de alto nível \texttt{run\_ast\_analysis}, que percorre recursivamente o repositório alvo, selecionando apenas arquivos Python cujo caminho não contenha o termo \texttt{``test''}. Para cada arquivo elegível, o código-fonte é lido, seus comentários são indexados por linha e, em seguida, a função \texttt{ast.parse} é invocada para produzir a AST nativa do Python. Com base nessa AST, o módulo \texttt{astcore.walker} executa a estratégia de travessia configurada, criando um \texttt{TNode} para cada nó visitado e aplicando, em cada fase (\texttt{PRE}, \texttt{ENRICH}, \texttt{POST}), os passes registrados no \texttt{PassRegistry}. Cada pass enriquece o \texttt{TNode} apenas com os campos sob sua responsabilidade (informações de caminho, nomes e visibilidade, características de classes e métodos, docstrings, comentários, métricas do grafo de chamadas, entre outros), resultando em uma árvore sintática enriquecida que serve como modelo intermediário estruturado para as etapas subsequentes de geração de embeddings e extração de casos de uso. 

\paragraph{Escolha da estratégia de travessia da AST}

A literatura de engenharia reversa não apresenta um consenso único sobre a
melhor forma de percorrer a AST; diferentes estratégias são adotadas em função
do objetivo da análise. Abordagens clássicas voltadas à recuperação de
comportamento e de fluxos de execução tendem a empregar \emph{depth-first
search} em pós-ordem (\emph{DFS post-order}). No contexto da ferramenta
REVUML, por exemplo, \textcite{Fauzi2016AST} argumentam que a travessia
pós-ordem é mais adequada para preservar a sequência das instruções no código
e, assim, apoiar a geração de diagramas de sequência e a reconstrução da
ordem de execução.

Por outro lado, trabalhos recentes focados em representação vetorial de código e em modelos neurais para compreensão de programas têm privilegiado variantes de pré-ordem. Estudos como o de \textcite{LiangHuang2024ASTLLM} mostram que a linearização da AST em pré-ordem (especialmente na forma \emph{reverse pre-order}) produz sequências mais estáveis e informativas para técnicas de \emph{tree positional encoding} e embeddings estruturais, levando a ganhos consistentes em tarefas de classificação, sumarização e \emph{clustering} de código.

Considerando que o objetivo deste trabalho não é reconstruir fielmente a ordem de execução, mas extrair padrões estruturais da árvore para alimentar uma GNN e algoritmos de \emph{clustering}, adotou-se a travessia em pré-ordem recursiva. Essa escolha favorece a preservação da hierarquia sintática (pai–filhos) na sequência linearizada e, consequentemente, a qualidade dos embeddings gerados a partir dos \texttt{TNode}s, alinhando-se às evidências empíricas da literatura recente em compreensão automática de código.

\paragraph{Arquitetura modular da construção da AST}

A Figura~\ref{fig:astcore_plugins_arch} apresenta a arquitetura responsável pela construção da árvore sintática enriquecida. O processo segue um microkernel de análise estática: o núcleo \texttt{astcore} concentra os mecanismos genéricos de travessia da AST, o registro e a ordenação de passes, além das estruturas do modelo intermediário (\texttt{TNode} e \texttt{Ctx}).

O \texttt{walker} coordena a travessia, combinando a estratégia selecionada (\texttt{Traversal}) com o conjunto de passes registrados no \texttt{PassRegistry}. A cada nó visitado, um \texttt{TNode} é criado e enriquecido pelos passes aplicáveis.

O enriquecimento propriamente dito é realizado pelos plugins definidos em \texttt{pass\_plugins}. Esses módulos são carregados dinamicamente pelo \texttt{Loader}, que registra seus \texttt{PassSpec}s no núcleo. Essa separação permite estender a análise sem modificar o microkernel.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Images/diagrams/diagrama_de_componentes_da_arquitetura_de_plugins.png}
    \caption{Arquitetura modular do núcleo de análise sintática (\texttt{astcore}) e da camada de plugins.}
    \label{fig:astcore_plugins_arch}
\end{figure}

\subsubsection{Geração de embeddings e grafo de código}

Na segunda etapa, o modelo intermediário estruturado, composto pelos \texttt{TNode}s produzidos pela AST enriquecida, é transformado em um modelo intermediário vetorial. O objetivo é codificar cada elemento do código-fonte em um vetor denso que capture, simultaneamente, propriedades estruturais (tipo reduzido do nó, profundidade, visibilidade, papel lógico na AST reduzida e métricas locais) e propriedades semânticas inferidas a partir de nomes, docstrings e comentários.

Cada \texttt{TNode} carrega um conjunto consolidado de atributos derivados dos passes do microkernel, abrangendo: tipo sintático reduzido, visibilidade, tipo de classe e tipo de método, papel lógico na AST reduzida (\texttt{core\_kind}), métricas estruturais como \texttt{fan\_in}, \texttt{fan\_out}, número de bases e decoradores, informações posicionais e elementos textuais associados (docstrings, comentários e tokens do identificador). Esse conjunto de informações serve como entrada direta para o processo de vetorização descrito a seguir.

\paragraph{Combinação de features estruturais e textuais}

A geração de embeddings por nó é organizada em três componentes: (a) a codificação estrutural, (b) a construção de uma representação textual consolidada e (c) a projeção conjunta dessas informações por meio de um codificador neural (\texttt{TNodeMLPEncoder}).

\emph{(a) Vetor estrutural.}
A função \texttt{structural\_features(t)} converte cada \texttt{TNode} em um vetor contínuo de dimensão fixa (\texttt{STRUCT\_DIM}). Esse vetor combina representações \emph{one-hot} para cinco atributos categóricos, tipo reduzido do nó, visibilidade, tipo de classe, tipo de método e papel lógico (\texttt{core\_kind}), com 14 valores numéricos que incluem profundidade na AST, número de parâmetros, número de exceções levantadas, classes-base, decoradores, chamadas locais, além de métricas de dependência (\texttt{fan\_in} e \texttt{fan\_out}) normalizadas por transformações logarítmicas.

\emph{(b) Representação textual via SBERT.}
De forma complementar, cada \texttt{TNode} é associado a uma descrição textual construída pela função \texttt{concat\_text\_from\_tnode}. Essa descrição reúne elementos semânticos relevantes, como nome qualificado, tokens do identificador, estilo de nomeação (\emph{snake\_case}, \emph{camelCase}, \emph{PascalCase}), docstrings, comentários e expressões de retorno. A inclusão explícita das convenções de nomeação (CamelCase e snake\_case) segue evidências recentes na literatura, que mostram que a decomposição semântica de identificadores melhora a capacidade do modelo de inferir o papel estrutural e funcional dos elementos do código \textcite{Ahmad2020TransformerCodeSummarization}. No presente trabalho, o texto consolidado é truncado em 512 caracteres e codificado por SBERT, gerando um embedding semântico de dimensão fixa (\texttt{TEXT\_EMB\_DIM}), podendo ser ajustado.

\emph{(c) Codificação conjunta por MLP.}
As representações estrutural e textual são concatenadas e projetadas por um codificador neural definido em \texttt{tnode\_encoder.py}. O \texttt{TNodeMLPEncoder} aplica uma normalização \texttt{LayerNorm} seguida de duas camadas densas: uma intermediária com 256 unidades e uma camada final que produz o embedding com dimensão \texttt{out\_dim} (tipicamente 128). O módulo atua como um \emph{fusion encoder}, aprendendo uma projeção conjunta que integra a estrutura sintática explícita, as métricas derivadas dos passes e a semântica condensada por SBERT.

O resultado desse processo é um embedding único para cada \texttt{TNode}, que combina de forma equilibrada informações estruturais e semânticas e serve como entrada para a etapa subsequente, na qual a \texttt{CodeGNN} modela o grafo sintático do arquivo e produz embeddings de nível de nó, arquivo e repositório.

\paragraph{Construção explícita do grafo da AST}

Após a vetorização dos \texttt{TNode}s, cada arquivo é convertido em um grafo que representa diretamente a estrutura sintática do código-fonte. Os vértices do grafo correspondem aos \texttt{TNode}s identificados na análise estática, enquanto as arestas conectam cada nó ao seu pai e aos seus filhos na AST. Essas conexões são tratadas como bidirecionais, permitindo que a rede capture tanto informações ascendentes quanto descendentes na hierarquia sintática.

Cada vértice recebe ainda um laço (\emph{self-loop}), assegurando que suas próprias informações locais sejam preservadas durante a agregação das camadas de convolução. Essa prática segue a formulação de Graph Convolutional Networks proposta por \textcite{KipfWelling2017GCN}, na qual a matriz de adjacência é expandida com auto-conexões para que o nó contribua explic

\section{Escolha dos repositórios}

Para a análise foram escolhidos três repositórios independentes, dois de David Beazley e um de Brandon Rhodes, duas referências em linguagem Python. Os repositórios de David Beazley possuem documentação completa no próprio repositório, facilitando a compreensão do software construído. Já o repositório de Brandon Rhodes não contém documentação, mas seu conteúdo é a adaptação do jogo \emph{Colossal Cave Adventure} de Fortran para Python.


\subsection{Colossal Cave Adventure}
Este trabalho utiliza como base uma reimplementação de \textcite{rhodes_adventure_py} em Python 3, que preserva o jogo original de Crowther e Don Woods, utilizando o arquivo de dados \texttt{advent.dat} \textcite{adventure_original_sources}. O pacote permite jogar em dois modos, no \emph{prompt} do Python e em terminal do sistema operacional. Além disso, disponibiliza \textit{walkthroughs} automatizados na pasta de testes.

\subsection{Descrição do jogo}

\textit{Colossal Cave Adventure}, também conhecido como \textit{ADVENT} ou simplesmente \textit{Adventure}, é amplamente reconhecido como o primeiro jogo de aventura baseado em texto da história, criado por Will Crowther em meados de 1975 e expandido por Don Woods em 1976. 

Ambientado em uma caverna repleta de tesouros, criaturas e labiríntos, o jogador interage por comandos de texto, como \textit{"GO NORTH"} ou \textit{"GET LAMP"}. O sistema responde com descrições que narram as consequências das ações.

Como observa \textcite{dibbell1998mytinylife}, o jogo automatiza o papel do mestre (\textit{Dungeon Master}) característico de campanhas de \textit{Dungeons and Dragons}. Suas descrições textuais simulam a fala do mestre (“\textit{YOU ARE IN A MAZE OF TWISTY LITTLE PASSAGES, ALL ALIKE}”).  

“Como qualquer programa significativo, \textit{Adventure} expressava a personalidade e o ambiente de seus autores.” \textcite{levy2010hackers}

Will Crowther e sua ex-esposa, Patricia Crowther, ambos programadores e espeleólogos, participaram do mapeamento do sistema de cavernas \textit{Mammoth Cave}. No verão de 1974, enquanto jogava campanhas de \textit{Dungeons and Dragons}, Will começou o desenvolvimento do seu jogo utilizando o Fortran. O mapa utilizado no jogo foi inspirado diretamente nos levantamentos realizados pelo casal durante as expedições à Mammoth Cave, construindo no código a estrutura real da caverna.

Como o próprio Will Crowther relata, a ideia do jogo surgiu da combinação entre suas experiências em espeleologia e seu interesse por \textit{Dungeons and Dragons}: “Eu estava envolvido em um jogo de interpretação de papéis... e tive uma ideia que combinasse o meu interesse por exploração de cavernas com algo que também fosse um jogo para as crianças...” \textcite{peterson1983genesis}.

\textcite{levy2010hackers} conta como inicia a colaboração de Donald Woods, um pesquisador da \textit{Stanford Artificial Intelligence Laboratory} (SAIL), em 1976. Após ter contato com uma prévia do jogo, Woods entrou em contato com Crowther, obteve sua permissão e passou a expandir o código. Sua versão incorporou novos puzzles, criaturas e elementos de fantasia inspirados na obra de Tolkien, além de um sistema de pontuação que estabelecia um objetivo ao jogador. A versão combinada de Crowther e Woods é um marco na história da interação humano-computador.

\subsection{}
Como o jogo não possui documentação original, utilizei o artigo de \textcite{jerz2007colossal} como referência para compreender a estrutura e o funcionamento do código. O autor recupera e examina o código-fonte escrito por Will Crowther, a partir de um backup preservado no SAIL. Jerz descreve as seis tabelas centrais que organizam os dados do jogo: descrições longas, rótulos curtos das salas, dados de mapa, vocabulário agrupado, estados estáticos e eventos ou dicas.  

Essa arquitetura de dados é mantida na reimplementação em Python, embora expandida para doze seções, resultado da integração da versão de Don Woods \textcite{rhodes_adventure_py}. A leitura e o processamento dessas tabelas ocorrem por meio do arquivo \texttt{advent.dat}, que preserva a semântica e a estrutura do código original. 

As seis tabelas descritas por Crowther estruturam o mundo do jogo e suas interações:
\begin{enumerate}
    \item \textbf{Long Descriptions}: textos descritivos longos que definem os ambientes e estados narrativos;
    \item \textbf{Short Room Labels}: nomes curtos usados internamente para identificar locais e facilitar a navegação;
    \item \textbf{Map Data}: conexões topológicas entre os ambientes e as direções de movimento possíveis;
    \item \textbf{Grouped Vocabulary Keywords}: agrupamento de palavras-chave e comandos interpretados pelo sistema;
    \item \textbf{Static Game States}: variáveis e condições fixas que controlam a lógica do jogo;
    \item \textbf{Hints and Events}: mensagens de ajuda, eventos dinâmicos e respostas a situações específicas.
\end{enumerate}

As outras seis adicionadas na versão em colaboração com Woods são:

\begin{enumerate}
  \item \emph{Object locations} — localização dos objetos;
  \item \emph{Action defaults} — mensagens padrão ligadas a verbos de ação;
  \item \emph{Liquid assets / flags} — \texttt{COND} por sala (luz, líquidos, restrições do pirata, bits de dicas);
  \item \emph{Class messages} — faixas de pontuação e mensagens de classificação do jogador;
  \item \emph{Hints} — dicas (turnos necessários, penalidade, pergunta e resposta);
  \item \emph{Magic messages} — mensagens de inicialização e manutenção.
\end{enumerate}

\paragraph{Tabela 1 – Long Descriptions.}  
A Tabela 1 contém descrições extensas dos ambientes do jogo. Com entradas identificadas de 1 a 140, ela define os textos apresentados ao jogador em diferentes locais. Cada linha representa uma sala ou estado narrativo. Parte dessas descrições refere-se diretamente a locais da caverna, como o trecho “\textit{YOU ARE STANDING AT THE END OF A ROAD BEFORE A SMALL BRICK BUILDING}”, enquanto outras descrevem situações de falha ou eventos inesperados, como “\textit{YOU ARE AT THE BOTTOM OF THE PIT WITH A BROKEN NECK}”.  

Exemplos:  
\begin{itemize}
    \item 1	\textit{AROUND YOU IS A FOREST.  A SMALL STREAM FLOWS OUT OF THE BUILDING AND DOWN A GULLY}.
    \item 2	\textit{YOU HAVE WALKED UP A HILL, STILL IN THE FOREST.  THE ROAD SLOPES BACK DOWN THE OTHER SIDE OF THE HILL.  THERE IS A BUILDING IN THE DISTANCE.}
    \item 3	\textit{YOU ARE INSIDE A BUILDING, A WELL HOUSE FOR A LARGE SPRING.}
\end{itemize}

\paragraph{Tabela 2 – Short Room Labels.}  
A Tabela 2 contém rótulos curtos correspondentes às localizações/ambientes do jogo. Com entradas numeradas de 1 a 130, nem todas as salas ou estados definidos em \textit{Long Descriptions} possuem equivalentes resumidos.  

Exemplos:  
\begin{itemize}
    \item 1 \textit{YOU'RE AT END OF ROAD AGAIN.}
    \item 3 \textit{YOU'RE INSIDE BUILDING.}
    \item 18 \textit{YOU'RE IN NUGGET OF GOLD ROOM.}
    \item 19 \textit{YOU'RE IN HALL OF MT KING.}
\end{itemize}

\paragraph{Tabela 3 – Map Data.}
A Tabela 3 codifica a topologia do mundo do jogo e as regras de navegação, funcionando como um grafo dirigido rotulado. A primeira coluna indica o ambiente em que o jogador se encontra, a segunda define o ambiente de destino, e as colunas subsequentes agrupam os vocabulários que podem ser utilizados para realizar a transição entre os dois pontos. O mapeamento dos vocabulários é definido na Tabela 4.  

Em alguns casos, o valor do destino representa uma condição especial, e não uma simples sala. Se o número de destino for maior que 500, o jogo exibe uma mensagem da Tabela 6 e o jogador permanece no mesmo local; Se estiver entre 300 e 500, o valor indica um salto especial para um trecho de código do jogo.
   
Exemplos:
\begin{itemize}
  \item 1  2  2  44  29: o jogador se desloca do ambiente 1 ao aombiente 2, se utilizados os comando 2, 44 ou 29. 
  \item 3  1  3  11  32  44: o jogador se desloca do ambiente 2 ao ambiente 1 se utilizados os comando 3, 11, 32 ou 44.
\end{itemize}

\paragraph{Tabela 4 – Grouped Vocabulary Keywords.}
No código original em Fortran, toda entrada de texto era truncada nos cinco primeiros caracteres, de modo que o comando \textit{“inventory”}, por exemplo, poderia ser digitado simplesmente como \textit{“inven”}. A reimplementação em Python de \textcite{rhodes_adventure_py} preserva essa lógica.  

Os dados da tabela 4 são divididos em 4 grupos: o primeiro com id's entre 1 e 100 para movimento no jogo; com ids entre 1000 e 2000, trata de objetos manipuláveis ou características de cenário; com ids entra 2000 e 3000 são verbos de ação, se entre 3000 e 4000 são para casos especiais.

\begin{itemize}
  \item 1–100: verbos de movimento, utilizados para navegação no espaço do jogo;  
  \item 1000–2000: objetos e elementos de cenário manipuláveis;  
  \item 2000–3000: verbos de ação (\textit{carry}, \textit{attack}, \textit{drop}, etc.);  
  \item 3000–4000: verbos de casos especiais, geralmente associados a eventos ou mensagens específicas definidas na Tabela 6.  
\end{itemize}

Além dos comandos clássicos de navegação por bússola, "\textit{EAST}"/"\textit{E}", "\textit{WEST}"/"\textit{W}", "\textit{NORTH}"/"\textit{N}", "\textit{SOUTH}"/"\textit{S}", parte dos veros de movimentos são nomes de locais da caverna como "\textit{BEDQU}" (truncamento de \textit{Bedquilt}), "\textit{HOUSE}", "\textit{GATE}" e "\textit{FORES}" (\textit{forest}).

Exemplos:  
\begin{itemize}
    \item 2 \textit{ROAD}
    \item 3 \textit{ENTER}
    \item 3 \textit{DOOR}
    \item 3 \textit{GATE}
    \item 4 \textit{UPSTR}
    \item 5 \textit{DOWNS}
    \item 6 \textit{FORES}
\end{itemize}

Palavras de mesmo sentido/sinônimos possuem mesmo id, como "\textit{ENTER}", "\textit{DOOR}" e "\textit{GATE}".

\paragraph{Tabela 5 – Static Game States.}  
A Tabela 5 armazena descrições curtas que representam estados do jogo, correspondendo às mudanças permanentes no ambiente. Cada linha contém um número e uma mensagem descritiva.  

Quando o identificador está entre 1 e 100, a linha define a mensagem de inventário associada a um objeto, exemplo: “\textit{SET OF KEYS}” se refere a "\textit{KEYS}". Quando o identificador é um múltiplo de 100, a mensagem descreve uma propriedado do objeto. 

Exemplos:  
\begin{itemize}
    \item 1	SET OF KEYS
    \item 000	THERE ARE SOME KEYS ON THE GROUND HERE.
    \item 2	BRASS LANTERN
    \item 000	THERE IS A SHINY BRASS LAMP NEARBY.
    \item 100	THERE IS A LAMP SHINING NEARBY.
    \item 3	*GRATE
    \item 000	THE GRATE IS LOCKED.
    \item 100	THE GRATE IS OPEN.
\end{itemize}

\paragraph{Tabela 6 – Hints and Events.}
A Tabela 6 reúne mensagens arbitrárias usadas como dicas e como descrições de eventos pontuais. Essas mensagens não estão relacionadas a um ambiente ou objeto específicos, elas são acionadas por outras estruturas do jogo, como as tabelas 3, 4, 8 e 11.

Exemplos:
\begin{enumerate}
    \item 3	AXE AT YOU WHICH MISSED, CURSED, AND RAN AWAY.
    \item 6	NONE OF THEM HIT YOU!
    \item 13 I DON'T UNDERSTAND THAT!
    \item 24 YOU ARE ALREADY CARRYING IT!
    \item 33 I DON'T KNOW HOW TO LOCK OR UNLOCK SUCH A THING.
\end{enumerate}

\paragraph{Tabela 7 – Object Locations.}
A Tabela 7 define onde cada objeto surge no mundo do jogo e se ele é móvel ou fixo. Cada linha possui o identificador do objeto, a sala inicial, e um campo opcional que indica imobilidade (-1) ou uma segunda sala quando o objeto existe simultaneamente em dois lugares 

\begin{itemize}
  \item Sala inicial = 0: o objeto não aparece no mundo no início e só será criado por algum evento ou ação do jogador.
  \item Terceiro campo = -1: o objeto está fixo naquela sala (não pode ser carregado).
  \item Terceiro campo = número de sala: o objeto está presente em duas salas ao mesmo tempo, objetos com duas localizações são tratados como imóveis.
\end{itemize}

Exemplos:
\begin{itemize}
  \item 1 3: objeto 1 (1001 - KEY, KEYS) começam na sala 3 (INSIDE BUILDING).
  \item 2 3: objeto 2 (1002 - LAMP, HEADL, LANTE) começam na sala 3 (INSIDE BUILDING).
  \item 3 8 9: objeto 3 (1003 - grate) existe nas salas 8 e 9 simultaneamente (8 - YOU'RE OUTSIDE GRATE, 9 - YOU'RE BELOW THE GRATE.).
  \item (9 - DOOR) (94 - YOU ARE AT ONE END OF AN IMMENSE NORTH/SOUTH PASSAGE.)
  \item 9 94 -1: objeto 9 (1009 - DOOR) é fixo na sala 94 (94 - YOU ARE AT ONE END OF AN IMMENSE NORTH/SOUTH PASSAGE.).
  \item 15 0: objeto 15 (1015 - OYSTE) começa fora do mundo e aparece mais tarde.
\end{itemize}

\paragraph{Tabela 8 – Action Defaults.}  
A Tabela 8 define o comportamento padrão dos verbos de ação, associando cada identificador de verbo ao índice da mensagem correspondente na Tabela 6. Cada linha contém dois valores: o primeiro é o número do verbo de ação, e o segundo é o identificador da mensagem padrão que deve ser exibida.

Exemplos:  
\begin{itemize}
  \item 1 24: o verbo de ação associado ao id 1 (2001 - CARRY, TAKE, KEEP, CATCH, STEAL, CAPTU, GET, TOTE) e a mensagem 24 da tabela 6 (YOU ARE ALREADY CARRYING IT!). 
  \item 6 33: o verbo de ação associado ao id 6 (2006 - LOCK, CLOSE) e a mensagem 33 da tabela 6 (I DON'T KNOW HOW TO LOCK OR UNLOCK SUCH A THING.).
  \item 7 38: o verbo de ação associado ao id 7 (2007 - LIGHT, ON) e a mensagem 38 da tabela 6 (YOU HAVE NO SOURCE OF LIGHT.). 
\end{itemize}

\paragraph{Tabela 9 – Liquid Assets, Etc.}
A Tabela 9 define os bits de condição associados a cada sala, controlando luz, líquidos, presença de inimigos e zonas de interesse para as rotinas de dicas. Cada linha contém um identificador de bit e uma lista de até vinte localizações nas quais esse bit é ativado. O jogo usa esses bits para determinar o comportamento dinâmico de cada ambiente.

\begin{itemize}
  \item 0: indica que o ambiente está naturalmente iluminado.
  \item 1: tipo de líquido usado em conjunto com o bit 2. Quando o bit 2 está ativo, este bit diferencia óleo (1) de água (0).
  \item 2: marca as salas que contêm água ou óleo.
  \item 3: impede que o pirata apareça ali, exceto quando persegue o jogador.
  \item 4: jogador tentando entrar na caverna.
  \item 5: tentativa de capturar o pássaro.
  \item 6: interação com a cobra.
  \item 7: perdido no labirinto.
  \item 8: refletindo no quarto escuro.
  \item 9: na área final Witt's End.
\end{itemize}

Exemplos:
\begin{itemize}
  \item 0 1 2 3 4 5 6 7 8 9 10 100 115 116 126: salas naturalmente iluminadas próximas à entrada.
  \item 2 1 3 4 7 38 95 113 24: presença de líquido (água ou óleo) nessas salas.
  \item 9 108: marca a área final do jogo, Witt’s End.
\end{itemize}

\paragraph{Tabela 10 – Class Messages.}
A Tabela 10 contém as mensagens de classificação do jogador de acordo com a pontuação total atingida ao final da partida. Cada linha associa um limite superior de pontuação a uma mensagem que descreve o título ou o nível de habilidade alcançado.  

Exemplos:
\begin{itemize}
  \item 35: YOU ARE OBVIOUSLY A RANK AMATEUR.  BETTER LUCK NEXT TIME.
  \item 100: YOUR SCORE QUALIFIES YOU AS A NOVICE CLASS ADVENTURER.
  \item 130: YOU HAVE ACHIEVED THE RATING: ‘EXPERIENCED ADVENTURER’.
  \item 200: YOU MAY NOW CONSIDER YOURSELF A ‘SEASONED ADVENTURER’.
  \item 250: YOU HAVE REACHED ‘JUNIOR MASTER’ STATUS.
  \item 300: MASTER ADVENTURER CLASSES C.
  \item 330: MASTER ADVENTURER CLASSES B.
  \item 349: MASTER ADVENTURER CLASSES A.
  \item 9999: ALL OF ADVENTUREDOM GIVES TRIBUTE TO YOU, ADVENTURER GRANDMASTER!
\end{itemize}

\paragraph{Tabela 11 – Hints.}
A Tabela 11 associa dicas contextuais a condições determinadas de jogo.  
Cada linha contém cinco valores:  

\begin{itemize}
  \item O primeiro valor vincula a dica a uma condição definidos na Tabela 9.
  \item O segundo valor define quantos turnos o jogador deve gastar no mesmo estado antes da dica ser oferecida.
  \item O terceiro valor representa a penalidade subtraída da pontuação total ao aceitar a ajuda.
  \item Os dois últimos valores apontam para mensagens da Tabela 6: a pergunta inicial e a resposta.
\end{itemize}

Exemplos:
\begin{itemize}
  \item 4 4 2 62 63 — Bit 4 (entrada da caverna): após 4 turnos no local, o jogo exibe a pergunta 62 (Do you need help getting inside?) e, se aceita, mostra a resposta 63 (Perhaps you should explore the grate.), descontando 2 pontos.
  \item 6 8 2 20 21 — Bit 6 (cobra): depois de 8 turnos, o jogador recebe uma dica para resolver o enigma da serpente.
  \item 7 75 4 176 177 — Bit 7 (labirinto): após 75 turnos perdido, é oferecida uma dica de saída, com penalidade de 4 pontos.
  \item 8 25 5 178 179 — Bit 8 (quarto escuro): a dica surge depois de 25 turnos, custando 5 pontos.
\end{itemize}

\paragraph{Tabela 12 – Magic Messages.}
A Tabela 12 contém as chamadas \textit{Magic Messages}, um conjunto de mensagens reservadas utilizadas pelos modos de inicialização, manutenção e administração do jogo.  
Embora seu formato seja idêntico ao da Tabela 6, elas são separadas para facilitar o acesso e o controle das rotinas especiais do sistema. Cada linha contém um identificador e um texto associado.agens internas do sistema.

Exemplos
\begin{itemize}
  \item 1 \textit{A LARGE CLOUD OF GREEN SMOKE APPEARS IN FRONT OF YOU… HE MAKES A SINGLE PASS OVER YOU WITH HIS HANDS, AND EVERYTHING FADES AWAY INTO A GREY NOTHINGNESS.}
  \item 2 \textit{EVEN WIZARDS HAVE TO WAIT LONGER THAN THAT!}
  \item 3 \textit{I'M TERRIBLY SORRY, BUT COLOSSAL CAVE IS CLOSED. OUR HOURS ARE:}
  \item 4 \textit{ONLY WIZARDS ARE PERMITTED WITHIN THE CAVE RIGHT NOW.}
\end{itemize}

\newpage

\printbibliography

\end{document}
